### Fine-Tuning and Retrieval Augmented Generation (RAG) with Mistral 7B

#### Overview
This project showcases how to fine-tune Mistral-7B using LoRA/PEFT and build a Retrieval-Augmented Generation (RAG) pipeline.
It also integrates CrewAI for agent orchestration.
The solution is designed for insurance data analytics, where fine-tuning + RAG helps improve accuracy and contextual understanding

#### ğŸ—ï¸ Features

ğŸ”¥ Fine-tuning Mistral-7B with LoRA adapters

ğŸ” RAG pipeline powered by FAISS and LangChain

ğŸ¤– CrewAI integration for orchestrating multi-agent reasoning

### Install Dependencies
pip install -r requirements.txt

### ğŸ“Š Results

âœ… Fine-tuned model improves domain-specific Q&A

âœ… RAG enhances factual accuracy with external data sources

RAG 
<img width="1814" height="725" alt="image" src="https://github.com/user-attachments/assets/7c5c8938-1b1a-44b1-bc3e-804c7e1448ae" />

Crew AI 
<img width="1759" height="241" alt="image" src="https://github.com/user-attachments/assets/109d82fe-a028-42d7-8571-1c365cce1e8e" />


